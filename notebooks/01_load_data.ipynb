{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcc8223",
   "metadata": {},
   "source": [
    "# 1. Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e8c66",
   "metadata": {},
   "source": [
    "## Import dependencies, set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96f109",
   "metadata": {},
   "source": [
    "1. `python3 -m venv .venv`\n",
    "2. utilize virtual environment\n",
    "    - (LINUX/MAC) `source .venv/bin/activate`\n",
    "    - (WINDOWS) `.venv\\Scripts\\Activate.    ps1`\n",
    "3. `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e55a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter magic\n",
    "%run ../util/dependencies.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98389ba",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddeb4ae",
   "metadata": {},
   "source": [
    "Upon reviewing the quality of data from the \"Planetary Systems\" (PS) database, it was deemed better to pivot towards the \"Planetary Systems Composite Data\" (PSCompPars) database. In brief:\n",
    "1. PS details a record for each exoplanet and each one of its references (this helps us reach original literature analyses of these bodies). Missing data is prevelant.\n",
    "2. PSCompPars curates a “best available” or “most complete” set of parameters for each planet, pulling from multiple references.\n",
    "\n",
    "So far as our exploration of exoplanets and their stars (studying the whole population of exoplanets thus far), this seems outside the scope of our analysis, and creates a cumbersome process of exploring the data. This will aid in limiting time spent cleaning the dataset, and limit our analysis to 6065 from a daunting ~32,000 records.\n",
    "\n",
    "For an explanation on how the composite dataset aggregates all available information on exoplanet figures, please see <https://exoplanetarchive.ipac.caltech.edu/docs/pscp_calc.html>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da9c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of records: 6065\n",
      "Data saved as 'pscp_01_raw.csv'\n"
     ]
    }
   ],
   "source": [
    "# TAP base URL (Planetary Systems Composite Data)\n",
    "url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "# The \"Planetary Systems Composite Data\" database (confirmed exoplanets) is encoded as \"PSCompPars\" within the Exoplanet Archive\n",
    "ADQL_query =    \"SELECT \" \\\n",
    "                \"pl_controv_flag, pl_name, hostname, pl_letter, sy_snum, discoverymethod, disc_year,\" \\\n",
    "                \"pl_radj, pl_massj, st_spectype, st_rad, st_mass, st_met, st_lum, st_teff, st_rad \" \\\n",
    "                \"FROM PSCompPars\"\n",
    "\n",
    "# Request data as CSV\n",
    "params = {\n",
    "    \"query\": ADQL_query,\n",
    "    \"format\": \"csv\"\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Load into \"Planetary Systems\" DataFrame\n",
    "pscp = pd.read_csv(io.StringIO(response.text))\n",
    "print(\"Data loaded successfully. Number of records:\", len(pscp))\n",
    "\n",
    "# Save to parquet for local use and following notebooks\n",
    "# (parquets are smaller files than csv, so good as an intermediate file type for future processing)\n",
    "file_name = 'pscp_01_raw.csv'\n",
    "\n",
    "try:\n",
    "    pscp.to_csv('../data/' + file_name, index=False)\n",
    "    print('Data saved as \\'' + file_name + '\\'')\n",
    "except Exception as e:\n",
    "    print('Data failed to save as \\'' + file_name + '\\': ' + e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab8fb0",
   "metadata": {},
   "source": [
    "Over 355 columns in this dataset!! All different features we can analyze in another related project pertaining to exoplanet exploration and methods for doing so . . .\n",
    "\n",
    "After reviewing the column descriptions (as defined here: <https://exoplanetarchive.ipac.caltech.edu/docs/API_PS_columns.html>), the following features are relevant to our exploration:\n",
    "1. pl_controv_flag (is the comfirmation of this planet questioned?)\n",
    "2. pl_name\n",
    "3. hostname (most common star name)\n",
    "4. pl_letter\n",
    "5. sy_snum\n",
    "6. discoverymethod\n",
    "7. disc_year\n",
    "8. pl_radj\n",
    "9. pl_massj\n",
    "10. st_spectype\n",
    "11. st_rad\n",
    "12. st_mass\n",
    "13. st_met\n",
    "14. st_lum\n",
    "15. st_rad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251e312",
   "metadata": {},
   "source": [
    "As we will see it later, it is important to get an overview of all of the stars we have seen in the observable universe thus far, to draw a picture of what exoplanet host (stellar) date is accessable to us, vs the stars that are in the observable universe. This is done as a means to detect bias from:\n",
    "1. **Educated Assumptions** Stars we choose to observe,\n",
    "2. **Technical Limitations** Stars are easier to observe, and\n",
    "3. **Physical Stellar Characteristics** Stars that tend to have more planets\n",
    "\n",
    "As such, the following dataset was appended to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5578361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of records: 990244\n",
      "Data saved as 'ks_01_raw.csv'\n"
     ]
    }
   ],
   "source": [
    "# TAP base URL (Kepler Stellar Table)\n",
    "url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "# The \"Kepler Stellar Table\" database (confirmed exoplanets) is encoded as \"keplerstellar\" within the Exoplanet Archive\n",
    "ADQL_query =    \"SELECT \" \\\n",
    "                \"kepid, tm_designation, teff, feh, radius, mass, dens, \" \\\n",
    "                \"nconfp, nkoi, ntce \" \\\n",
    "                \"FROM keplerstellar\"\n",
    "\n",
    "# Request data as CSV\n",
    "params = {\n",
    "    \"query\": ADQL_query,\n",
    "    \"format\": \"csv\"\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Load into \"Kepler Stellar\" DataFrame\n",
    "ks = pd.read_csv(io.StringIO(response.text))\n",
    "print(\"Data loaded successfully. Number of records:\", len(ks))\n",
    "\n",
    "# Save raw data as csv\n",
    "file_name = 'ks_01_raw.csv'\n",
    "\n",
    "try:\n",
    "    ks.to_csv('../data/' + file_name, index=False)\n",
    "    print('Data saved as \\'' + file_name + '\\'')\n",
    "except Exception as e:\n",
    "    print('Data failed to save as \\'' + file_name + '\\': ' + e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
